{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2Sqv9RoZaESBnr3HmsCYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/open-spaced-repetition/fsrs4anki/blob/main/fsrs4anki_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload your Anki Collection Package file or Anki Deck Package file. No need to include media. Need to include scheduling information.\n",
        "\n",
        "You can export it via `File -> Export...` or `Ctrl + E` in the main window of Anki.\n",
        "\n",
        "Then replace the `filename` with yours in the next code cell.\n",
        "\n",
        "After that, just run all (`Runtime -> Run all` or `Ctrl + F9`)."
      ],
      "metadata": {
        "id": "wG7bBfGJFbMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"ALL__Learnig.apkg\" \n",
        "# If you upload deck file, replace it with your deck filename. E.g., ALL__Learnig.apkg \n",
        "# If you upload collection file, replace it with your colpgk filename. E.g., collection-2022-09-18@13-21-58.colpkg\n",
        "\n",
        "import zipfile\n",
        "# Extract the collection file to get the .anki21 database.\n",
        "with zipfile.ZipFile(f'./{filename}', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')\n",
        "    print(\"Extract successfully!\")"
      ],
      "metadata": {
        "id": "iqP70_-3EUhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b060395-85fd-40de-e969-7d8bb0173f70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extract successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import time\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "FopqtQ7mMbA4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code cell will extract the review logs from your Anki collection and preprocess them to a trainset which is saved in `revlog_history.tsv`.\n",
        "\n",
        " The time-series features are important in optimizing the model's parameters. For more detail, please see my paper: https://www.maimemo.com/paper/"
      ],
      "metadata": {
        "id": "dKpy4VfqGmaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timezone = 'Asia/Shanghai'  # Replace it with your timezone. I'm in China, so I use Asia/Shanghai.\n",
        "next_day_starts_at = 6  # Replace it with your Anki's setting in Prefernces -> Scheduling.\n",
        "\n",
        "con = sqlite3.connect(\"collection.anki21\")\n",
        "cur = con.cursor()\n",
        "res = cur.execute(\"SELECT * FROM revlog\")\n",
        "revlog = res.fetchall()\n",
        "\n",
        "df = pd.DataFrame(revlog)\n",
        "df.columns = ['id', 'cid', 'usn', 'r', 'ivl', 'last_lvl', 'factor', 'time', 'type']\n",
        "df = df[(df['cid'] <= time.time() * 1000) & (df['id'] <= time.time() * 1000)]\n",
        "df['create_date'] = pd.to_datetime(df['cid'] // 1000, unit='s')\n",
        "df['create_date'] = df['create_date'].dt.tz_localize('UTC').dt.tz_convert(timezone)\n",
        "df['review_date'] = pd.to_datetime(df['id'] // 1000, unit='s')\n",
        "df['review_date'] = df['review_date'].dt.tz_localize('UTC').dt.tz_convert(timezone)\n",
        "df.sort_values(by=['cid', 'id'], inplace=True, ignore_index=True)\n",
        "df.to_csv(\"revlog.csv\", index=False)\n",
        "df = df[(df['type'] == 0) | (df['type'] == 1)]\n",
        "df['real_date'] = df['review_date'].map(lambda x: x - timedelta(days=1) if x.hour < next_day_starts_at else x)\n",
        "df['real_date'] = df['real_date'].dt.floor('D')\n",
        "df.drop(df[df['real_date'].dt.year < 2006].index, inplace=True)\n",
        "df.drop_duplicates(['cid', 'real_date'], keep='first', inplace=True)\n",
        "df['delta_t'] = df.real_date.diff().dt.days\n",
        "df.dropna(inplace=True)\n",
        "df['delta_t'] = df['delta_t'].astype(dtype=int)\n",
        "df['i'] = 1\n",
        "df['r_history'] = \"\"\n",
        "df['t_history'] = \"\"\n",
        "col_idx = {key: i for i, key in enumerate(df.columns)}\n",
        "\n",
        "\n",
        "# code from https://github.com/L-M-Sherlock/anki_revlog_analysis/blob/main/revlog_analysis.py\n",
        "def get_feature(x):\n",
        "    for idx, log in enumerate(x.itertuples()):\n",
        "        if idx == 0:\n",
        "            x.iloc[idx, col_idx['delta_t']] = 0\n",
        "        if idx == x.shape[0] - 1:\n",
        "            break\n",
        "        x.iloc[idx + 1, col_idx['i']] = x.iloc[idx, col_idx['i']] + 1\n",
        "        x.iloc[idx + 1, col_idx['t_history']] = f\"{x.iloc[idx, col_idx['t_history']]},{x.iloc[idx, col_idx['delta_t']]}\"\n",
        "        x.iloc[idx + 1, col_idx['r_history']] = f\"{x.iloc[idx, col_idx['r_history']]},{x.iloc[idx, col_idx['r']]}\"\n",
        "    return x\n",
        "\n",
        "\n",
        "tqdm.pandas()\n",
        "df = df.groupby('cid', as_index=False).progress_apply(get_feature)\n",
        "df[\"t_history\"] = df[\"t_history\"].map(lambda x: x[1:] if len(x) > 1 else x)\n",
        "df[\"r_history\"] = df[\"r_history\"].map(lambda x: x[1:] if len(x) > 1 else x)\n",
        "df.to_csv('revlog_history.tsv', sep=\"\\t\", index=False)\n",
        "print(\"Trainset saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2IIaY3PDaaG",
        "outputId": "f2f25b5b-6160-45a3-da0c-41e588d44aa7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5166/5166 [01:05<00:00, 79.32it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainset saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t_mnh8rqgyhs"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "import torch\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default parameters of FSRS."
      ],
      "metadata": {
        "id": "8ciBtn8FHAIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "defaultDifficulty = 5\n",
        "defaultStability = 2\n",
        "difficultyDecay = -0.7\n",
        "stabilityDecay = -0.2\n",
        "increaseFactor = 3\n",
        "lapsesBase = -0.3"
      ],
      "metadata": {
        "id": "KYugxP_DhMfm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FSRS is a time-series model for predicting memory states."
      ],
      "metadata": {
        "id": "WrfBJjqCHEwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FSRS(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FSRS, self).__init__()\n",
        "        self.f_s = nn.Parameter(torch.FloatTensor([defaultStability]))\n",
        "        # init stability\n",
        "        self.f_d = nn.Parameter(torch.FloatTensor([defaultDifficulty]))\n",
        "        # init difficulty\n",
        "        self.s_w = nn.Parameter(torch.FloatTensor(\n",
        "            [increaseFactor, difficultyDecay, stabilityDecay, lapsesBase]))\n",
        "        self.zero = torch.FloatTensor([0.0])\n",
        "\n",
        "    def forward(self, x, s, d, l):\n",
        "        '''\n",
        "        :param x: [review interval, review response]\n",
        "        :param s: stability\n",
        "        :param d: difficulty\n",
        "        :param l: lapses\n",
        "        :return:\n",
        "        '''\n",
        "        if torch.equal(s, torch.FloatTensor([0.0])):\n",
        "            # first learn, init memory states\n",
        "            next_s = self.f_s[0] * 0.25 * torch.pow(2, x[1] - 1)\n",
        "            next_d = self.f_d[0] - x[1] + 3\n",
        "            next_l = torch.relu(2-x[1])\n",
        "        else:\n",
        "            next_s = (1 - torch.relu(2-x[1])) * s * \\\n",
        "                             (1 + torch.exp(self.s_w[0]) * torch.pow(d + 0.1, self.s_w[1]) *\n",
        "                              torch.pow(s, self.s_w[2]) *\n",
        "                              (torch.exp(1 - torch.exp(np.log(0.9) * x[0] / s)) - 1)) + \\\n",
        "                             torch.relu(2-x[1]) * self.f_s[0] * torch.exp(self.s_w[3] * l)\n",
        "            next_d = torch.relu(d + torch.exp(np.log(0.9) * x[0] / s) - 0.25 * torch.pow(2, x[1] - 1) + 0.1)\n",
        "            next_l = l + torch.relu(2-x[1])\n",
        "        return next_s, next_d, next_l\n",
        "\n",
        "    def loss(self, s, t, r):\n",
        "        return - (r * np.log(0.9) * t / s + (1 - r) * torch.log(1 - torch.exp(np.log(0.9) * t / s)))\n",
        "\n",
        "\n",
        "class WeightClipper(object):\n",
        "    def __init__(self, frequency=1):\n",
        "        self.frequency = frequency\n",
        "\n",
        "    def __call__(self, module):\n",
        "        if hasattr(module, 'f_s'):\n",
        "            w = module.f_s.data\n",
        "            w = w.clamp(0.1, 10)\n",
        "            module.f_s.data = w\n",
        "        if hasattr(module, 'f_d'):\n",
        "            w = module.f_d.data\n",
        "            w = w.clamp(1, 10)\n",
        "            module.f_d.data = w\n",
        "        if hasattr(module, 's_w'):\n",
        "            w = module.s_w.data\n",
        "            w[0] = w[0].clamp(0.01, 10)\n",
        "            w[1] = w[1].clamp(-1, -0.01)\n",
        "            w[2] = w[2].clamp(-1, -0.01)\n",
        "            w[3] = w[3].clamp(-1, -0.01)\n",
        "            module.s_w.data = w\n",
        "\n",
        "\n",
        "def lineToTensor(line):\n",
        "    ivl = line[0].split(',')\n",
        "    response = line[1].split(',')\n",
        "    tensor = torch.zeros(len(response), 2)\n",
        "    for li, response in enumerate(response):\n",
        "        tensor[li][0] = int(ivl[li])\n",
        "        tensor[li][1] = int(response)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "tdYp3GMLhTYm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training approximately spends (the number of logs / 10000) minutes to optimize the parameters."
      ],
      "metadata": {
        "id": "8E1dYfgQLZAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FSRS()\n",
        "clipper = WeightClipper()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "dataset = pd.read_csv(\"./revlog_history.tsv\", sep='\\t', index_col=None)\n",
        "dataset = dataset[dataset['i'] > 1]\n",
        "\n",
        "n_epoch = 1\n",
        "print_len = dataset.shape[0] // 10\n",
        "\n",
        "checkpoint = {\n",
        "    \"net\": model.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "    \"epoch\": -1\n",
        "}\n",
        "\n",
        "for k in range(n_epoch):\n",
        "    dataset = shuffle(dataset, random_state=2022 + k)\n",
        "    epoch_len = len(dataset)\n",
        "    for i, (_, row) in enumerate(tqdm(dataset.iterrows(), total=epoch_len, position=0, leave=False, desc=\"train\",file=sys.stdout)):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        line_tensor = lineToTensor(\n",
        "            list(zip([row['t_history']], [row['r_history']]))[0])\n",
        "        output_t = [(model.zero, model.zero, model.zero)]\n",
        "        for input_t in line_tensor:\n",
        "            output_t.append(model(input_t, *output_t[-1]))\n",
        "        loss = model.loss(output_t[-1][0], row['delta_t'], {1: 0, 2: 1, 3: 1, 4: 1}[row['r']])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.apply(clipper)\n",
        "\n",
        "        if (k * epoch_len + i) % print_len == 0:\n",
        "            tqdm.write(f\"iteration: {k * epoch_len + i + 1}\")\n",
        "            for name, param in model.named_parameters():\n",
        "                tqdm.write(f\"{name}: {param}\")\n",
        "\n",
        "            checkpoint = {\n",
        "                \"net\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "                \"iteration\": (k * epoch_len + i) // print_len\n",
        "            }\n",
        "\n",
        "end = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "torch.save(checkpoint, f'./model-{end}.pth')\n",
        "\n",
        "defaultStability = round(float(dict(model.named_parameters())['f_s'].data),4)\n",
        "defaultDifficulty = round(float(dict(model.named_parameters())['f_d'].data),4)\n",
        "increaseFactor, difficultyDecay, stabilityDecay, lapsesBase = map(lambda x: round(float(x), 4), dict(model.named_parameters())['s_w'].data)\n",
        "\n",
        "print(\"Training finished!\")"
      ],
      "metadata": {
        "id": "Jht0gneShowU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb94420-5136-453c-f79a-1dde64620edd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0\n",
            "f_s: Parameter containing:\n",
            "tensor([2.0001], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([5.0001], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 2.9999, -0.7001, -0.2001, -0.3001], requires_grad=True)\n",
            "iteration: 5692\n",
            "f_s: Parameter containing:\n",
            "tensor([2.0582], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.8983], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.0868, -0.6227, -0.1480, -0.2712], requires_grad=True)\n",
            "iteration: 11384\n",
            "f_s: Parameter containing:\n",
            "tensor([2.1142], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.8193], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.1483, -0.5716, -0.1110, -0.2471], requires_grad=True)\n",
            "iteration: 17076\n",
            "f_s: Parameter containing:\n",
            "tensor([2.1938], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.7605], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.1875, -0.5427, -0.0908, -0.2096], requires_grad=True)\n",
            "iteration: 22768\n",
            "f_s: Parameter containing:\n",
            "tensor([2.2613], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.7326], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.1942, -0.5464, -0.0938, -0.1744], requires_grad=True)\n",
            "iteration: 28460\n",
            "f_s: Parameter containing:\n",
            "tensor([2.3360], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.7011], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.2070, -0.5427, -0.0979, -0.1278], requires_grad=True)\n",
            "iteration: 34152\n",
            "f_s: Parameter containing:\n",
            "tensor([2.3921], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.6779], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.2132, -0.5446, -0.1032, -0.1004], requires_grad=True)\n",
            "iteration: 39844\n",
            "f_s: Parameter containing:\n",
            "tensor([2.4557], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.6495], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.2256, -0.5404, -0.0972, -0.0765], requires_grad=True)\n",
            "iteration: 45536\n",
            "f_s: Parameter containing:\n",
            "tensor([2.5047], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.6369], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.2215, -0.5525, -0.1084, -0.0598], requires_grad=True)\n",
            "iteration: 51228\n",
            "f_s: Parameter containing:\n",
            "tensor([2.5559], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.6029], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.2343, -0.5508, -0.1086, -0.0495], requires_grad=True)\n",
            "iteration: 56920\n",
            "f_s: Parameter containing:\n",
            "tensor([2.5953], requires_grad=True)\n",
            "f_d: Parameter containing:\n",
            "tensor([4.5839], requires_grad=True)\n",
            "s_w: Parameter containing:\n",
            "tensor([ 3.2328, -0.5623, -0.1172, -0.0412], requires_grad=True)\n",
            "Training finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the optimal parameters for FSRS for you in the output of next code cell after running.\n",
        "\n",
        "The code of Anki custom scheduling is at https://github.com/open-spaced-repetition/fsrs4anki"
      ],
      "metadata": {
        "id": "BZ4S2l7BWfzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"const defaultDifficulty = {defaultDifficulty};\")\n",
        "print(f\"const defaultStability = {defaultStability};\")\n",
        "print(f\"const difficultyDecay = {difficultyDecay};\")\n",
        "print(f\"const stabilityDecay = {stabilityDecay};\")\n",
        "print(f\"const increaseFactor = {increaseFactor};\")\n",
        "print(f\"const lapsesBase = {lapsesBase};\")"
      ],
      "metadata": {
        "id": "NTnPSDA2QpUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0e485e-1255-4bb2-8149-0ecb8e48bdfa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "const defaultDifficulty = 4.5839;\n",
            "const defaultStability = 2.5952;\n",
            "const difficultyDecay = -0.5624;\n",
            "const stabilityDecay = -0.1172;\n",
            "const increaseFactor = 3.2327;\n",
            "const lapsesBase = -0.0412;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the memory states and intervals generated by FSRS as if you press the good in each review at the due date scheduled by FSRS."
      ],
      "metadata": {
        "id": "I_zsoDyTaTrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Collection:\n",
        "    def __init__(self):\n",
        "        self.model = model\n",
        "\n",
        "    def next_states(self, t_history, r_history):\n",
        "        with torch.no_grad():\n",
        "            line_tensor = lineToTensor(list(zip([t_history], [r_history]))[0])\n",
        "            output_t = [(self.model.zero, self.model.zero, self.model.zero)]\n",
        "            for input_t in line_tensor:\n",
        "                output_t.append(self.model(input_t, *output_t[-1]))\n",
        "            return output_t[-1]\n",
        "\n",
        "my_collection = Collection()\n",
        "t_history = \"0\"\n",
        "r_history = \"3\"\n",
        "for i in range(15):\n",
        "    states = my_collection.next_states(t_history, r_history)\n",
        "    print(states)\n",
        "    next_t = round(float(states[0]))\n",
        "    t_history += f',{int(next_t)}'\n",
        "    r_history += \",3\"\n",
        "print(t_history)"
      ],
      "metadata": {
        "id": "iws4rtP1WKBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dacf9e5-1e56-44da-e3fe-8fb91f654a4a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor(2.5952), tensor(4.5839), tensor(0.))\n",
            "(tensor(5.5947), tensor(4.5692), tensor(0.))\n",
            "(tensor(11.0884), tensor(4.5624), tensor(0.))\n",
            "(tensor(20.3944), tensor(4.5631), tensor(0.))\n",
            "(tensor(36.1469), tensor(4.5649), tensor(0.))\n",
            "(tensor(62.6541), tensor(4.5653), tensor(0.))\n",
            "(tensor(106.1411), tensor(4.5648), tensor(0.))\n",
            "(tensor(174.9307), tensor(4.5649), tensor(0.))\n",
            "(tensor(282.0350), tensor(4.5649), tensor(0.))\n",
            "(tensor(445.2276), tensor(4.5649), tensor(0.))\n",
            "(tensor(689.3261), tensor(4.5650), tensor(0.))\n",
            "(tensor(1048.3844), tensor(4.5650), tensor(0.))\n",
            "(tensor(1568.3268), tensor(4.5650), tensor(0.))\n",
            "(tensor(2310.3726), tensor(4.5651), tensor(0.))\n",
            "(tensor(3355.0225), tensor(4.5651), tensor(0.))\n",
            "0,3,6,11,20,36,63,106,175,282,445,689,1048,1568,2310,3355\n"
          ]
        }
      ]
    }
  ]
}